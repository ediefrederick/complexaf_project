{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from Bio.PDB import PDBParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_create_fasta(df, input_fasta, output_dir):\n",
    "    \"\"\"\n",
    "    Shuffle and create FASTA files based on updated selection rules.\n",
    "    Homomers have sequence IDs starting with 'T', heteromers start with 'H'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing targets and stoichiometry.\n",
    "        input_fasta (str): Path to the input FASTA file containing all sequences.\n",
    "        output_dir (str): Directory to save the new shuffled FASTA files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column `Target*` listing chosen subunits and their stoichiometry.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load all sequences from the input FASTA file\n",
    "    all_sequences = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "    sequence_dict = {rec.id: rec for rec in all_sequences}\n",
    "\n",
    "    # Create a lookup table for stoichiometry\n",
    "    stoichiometry_dict = {\n",
    "        row['Target'].split(\"s\")[0]: row['Stoichiometry'] for _, row in df.iterrows()\n",
    "    }\n",
    "\n",
    "    # Target IDs to exclude\n",
    "    excluded_targets = {\"H1111\", \"H1114\", \"T1115\", \"H1137\", \"H1166\", \"H1167\", \"H1168\", \"H1185\"}\n",
    "\n",
    "    chosen_subunits = []  # List to track chosen subunits for each target\n",
    "\n",
    "    # Process each target in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        target_id = row['Target']\n",
    "        original_stoichiometry = row['Stoichiometry']\n",
    "        subunit_counts = parse_stoichiometry(original_stoichiometry)\n",
    "        \n",
    "        # Get all sequences except those belonging to the current target and excluded targets\n",
    "        excluded_sequences = {\n",
    "            seq_id for seq_id in sequence_dict\n",
    "            if seq_id.split(\"s\")[0] in excluded_targets or seq_id.startswith(target_id.split(\"s\")[0])\n",
    "        }\n",
    "        valid_sequences = [\n",
    "            seq for seq_id, seq in sequence_dict.items() if seq_id not in excluded_sequences\n",
    "        ]\n",
    "\n",
    "        selected_sequences = []\n",
    "        selected_subunits = []  # Track selected subunit IDs with stoichiometry\n",
    "        used_multimers = set()  # Track multimers already used for replacement\n",
    "\n",
    "        for subunit, count in subunit_counts.items():\n",
    "            # Filter valid sequences based on the rules\n",
    "            filtered_sequences = []\n",
    "            for seq in valid_sequences:\n",
    "                seq_id = seq.id\n",
    "                seq_stoichiometry = stoichiometry_dict.get(seq_id.split(\"s\")[0], \"Unknown\")\n",
    "                seq_counts = parse_stoichiometry(seq_stoichiometry)\n",
    "\n",
    "                # Exclude same multimer\n",
    "                if seq_id.split(\"s\")[0] in used_multimers:\n",
    "                    continue\n",
    "\n",
    "                # Exclude same count for Xâ‰ 1\n",
    "                if count != 1 and any(subunit in seq_counts and seq_counts[subunit] == count for subunit in seq_counts):\n",
    "                    continue\n",
    "\n",
    "                filtered_sequences.append(seq)\n",
    "\n",
    "            # Randomly select a replacement sequence\n",
    "            chosen = random.sample(filtered_sequences, 1)[0]\n",
    "            selected_sequences.extend([chosen] * count)  # Repeat it count times\n",
    "            used_multimers.add(chosen.id.split(\"s\")[0])  # Mark multimer as used\n",
    "\n",
    "            # Add the sequence ID and its stoichiometry\n",
    "            original_seq_id = chosen.id.split(\"s\")[0]  # Extract ID before \"s\" if present\n",
    "            seq_stoichiometry = stoichiometry_dict.get(original_seq_id, \"Unknown\")\n",
    "            selected_subunits.append(f\"{chosen.id} ({seq_stoichiometry})\")\n",
    "        \n",
    "        # Write the new FASTA file\n",
    "        output_path = os.path.join(output_dir, f\"{target_id}.fasta\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            SeqIO.write(selected_sequences, f, \"fasta\")\n",
    "        \n",
    "        # Add selected subunits to the list\n",
    "        chosen_subunits.append(\",\".join(selected_subunits))\n",
    "    \n",
    "    # Add the new column to the DataFrame\n",
    "    df['Target*'] = chosen_subunits\n",
    "    return df\n",
    "\n",
    "def parse_stoichiometry(stoichiometry):\n",
    "    \"\"\"\n",
    "    Parse stoichiometry string (e.g., \"A2B3\") into a dictionary of subunits and counts.\n",
    "\n",
    "    Args:\n",
    "        stoichiometry (str): Stoichiometry string (e.g., \"A2B3\").\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with subunit labels as keys and counts as values.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"([A-Z])(\\d+)\")\n",
    "    return {match[0]: int(match[1]) for match in pattern.findall(stoichiometry)}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
